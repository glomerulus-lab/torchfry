import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from Layers.RKS_Layer import RKS_Layer
from Layers.FastFood_Layer import FastFood_Layer
from NN import run_NN
import pickle
import os
from collections import namedtuple
import numpy as np
import time

# Set device to CUDA if available, else fall back to CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Function to generate different hyperparameter combinations
# EDIT THIS TO TEST ON DESIRED HYPERPARAMETERS
def sweep_params():
    # Named tuple to hold each combination of hyperparameters
    IterationData = namedtuple("IterationData", 
        ["projection", "learnable", "learnable_gbs", "scale", "projection_dimensions", "epochs",
         "batch_size", "batch_norm", "lr"])

    # Define fixed values for some parameters
    epochs = 20
    batch_size = 512
    batch_norm = True
    lr = 0.0001
    scale = 1
    # projection_dimensions = [[1024, 1024], [2048, 2048], [4096, 4096], [8192, 8192], [16384, 16384]]
    projection_dimensions = [[128, 128], [256, 256]]

    for projection in ["rks", "ff"]:
        learnable = True
        learnable_gbs = [True, True, True]

        for proj_dim in projection_dimensions:
            yield IterationData(projection, 
                                "NA" if projection == "ff" else learnable, 
                                "NA" if projection == "rks" else learnable_gbs, 
                                scale, proj_dim, epochs, batch_size, batch_norm, lr)

# Function to parse command-line arguments
def parse_all_args():
    # Set up argument parser
    parser = argparse.ArgumentParser()

    # Define arguments for various hyperparameters
    parser.add_argument("--projection", type=str, choices=["ff", "rks"], help="Projection technique desired (ff or rks)", required=True)
    parser.add_argument("--learnable", type=bool, help="Learnable Projection weights (bool)", default=False)
    parser.add_argument("--learnable_gbs", type=list[bool], default=[False, False, False], help="Learnable Projection weights (list of bools)")
    parser.add_argument("--scale", type=float, default=1.0, help="Scale for projection (float)")
    parser.add_argument("--projection_dimensions", type=list[int], default=[2048, 4096, 8192], help="Projection dims by layer (list of ints)")
    parser.add_argument("--epochs", type=int, default=10, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=256, help="Batch size for training")
    parser.add_argument("--batch_norm", help="Use batch normalization (bool)", default=False)
    parser.add_argument("--lr", help="Learning rate of optimizer", default=0.1)

    return parser.parse_args()

# Iterate through all parameter combinations generated by the sweep_params function
for args in sweep_params():
    print(args)

    # Define data transformations for preprocessing
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),  # Normalize data to [-1, 1] range
        transforms.Pad(2, padding_mode="edge")  # Pad images by 2 pixels (edge padding)
    ])

    # Load FashionMNIST dataset
    trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
    testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)

    # Create data loaders for training and testing sets
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)
    testloader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=False)

    # Initialize model layers (moduleList will hold our layers)
    moduleList = nn.ModuleList()
    input_dim = 1024  # Initial input dimension

    # Define layers based on the projection type and configuration
    for i in range(len(args.projection_dimensions)):
        # Add projection layers based on selected type (RKS or FastFood)
        if args.projection == 'rks':
            moduleList.append(RKS_Layer(input_dim=input_dim, 
                                        output_dim=args.projection_dimensions[i], 
                                        scale=args.scale, 
                                        device=device, 
                                        learn_G=args.learnable,
                                        nonlinearity=False))
        else:  # FastFood Layer
            moduleList.append(FastFood_Layer(input_dim=input_dim, 
                                        output_dim=args.projection_dimensions[i], 
                                        scale=args.scale, 
                                        device=device, 
                                        learn_G=args.learnable_gbs[0],
                                        learn_B=args.learnable_gbs[1],
                                        learn_S=args.learnable_gbs[2],
                                        nonlinearity=False))
        
        # Optionally add batch normalization after each layer
        if args.batch_norm:
            moduleList.append(nn.BatchNorm1d(args.projection_dimensions[i], affine=False))

        # Nonlinearity (ReLU) after each layer
        moduleList.append(nn.ReLU())
        input_dim = args.projection_dimensions[i]  # Update input dimension for next layer

    # Output layer (final classification layer)
    moduleList.append(nn.Linear(input_dim, 10))  # 10 output classes for FashionMNIST

    # Initialize lists to store metrics per epoch for all runs
    train_accuracies_per_epoch_all_runs = []
    test_accuracies_per_epoch_all_runs = []
    elapsed_time_all_runs = []
    train_times_per_epoch_all_runs = []
    forward_pass_times_per_epoch_all_runs = []

    # Run the model 10 times to get accurate performance stats
    for run in range(10):
        print(f"Round {run+1}:")
        # Run the neural network and get performance metrics for each run
        learnable_params, non_learnable_params, train_accuracies, test_accuracies, elapsed_time, train_times, forward_pass_times = run_NN(trainloader, testloader, moduleList, args.epochs, device, args.lr)

        # Store the accuracies and times for each epoch in the current run
        train_accuracies_per_epoch_all_runs.append(train_accuracies)
        test_accuracies_per_epoch_all_runs.append(test_accuracies)
        elapsed_time_all_runs.append(elapsed_time)
        train_times_per_epoch_all_runs.append(train_times)
        forward_pass_times_per_epoch_all_runs.append(forward_pass_times)

    # Calculate the mean and std of accuracies and times across all 10 runs for each epoch
    train_accuracy_means = [np.mean(train_accuracies_per_epoch_all_runs)]
    train_accuracy_stds = [np.std(train_accuracies_per_epoch_all_runs)]
    test_accuracy_means = [np.mean(test_accuracies_per_epoch_all_runs)]
    test_accuracy_stds = [np.std(test_accuracies_per_epoch_all_runs)]

    # Ensure directory exists to save performance metrics
    os.makedirs("small_fry_experiment", exist_ok=True)

    # Build parts of the filename separately
    base = f"small_fry_experiment/{args.projection}"

    # Handle projection-specific parts
    if args.projection == 'rks':
        projection_part = f"-{args.learnable}"
    elif args.projection == 'ff':
        gbs_part = ''.join(['L' if g else 'N' for g in args.learnable_gbs])
        projection_part = f"-GBS_{gbs_part}"
    else:
        projection_part = "-GBS_"

    # Other filename components
    scale_part = f"-scale={args.scale}"
    proj_dims_part = f"-projdims=["
    for i, dim in enumerate(args.projection_dimensions):
        proj_dims_part += f"{dim}, " if i < len(args.projection_dimensions) - 1 else f"{dim}]"
    epoch_part = f"-epochs={args.epochs}"
    batch_part = f"-batch_size={args.batch_size}"
    batch_norm_part = f"-{'Yes' if args.batch_norm else 'No'}"
    lr_part = f"-lr={args.lr}"

    # Combine all parts
    filename = base + projection_part + scale_part + proj_dims_part + epoch_part + batch_part + batch_norm_part + lr_part + ".pkl"

    # Create a dictionary to store hyperparameters and performance metrics
    hyperparams_and_performance = {
        "hyperparameters": {
            "projection": args.projection,
            "learnable": args.learnable,
            "learnable_gbs": args.learnable_gbs,
            "scale": args.scale,
            "projection_dimensions": args.projection_dimensions,
            "epochs": args.epochs,
            "batch_size": args.batch_size,
            "batch_norm": args.batch_norm
        },
        "performance": {
            "learnable_params": learnable_params,
            "non_learnable_params": non_learnable_params,
            "train_accuracy_means": train_accuracy_means,
            "test_accuracy_means": test_accuracy_means,
            "train_accuracy_stds": train_accuracy_stds,
            "test_accuracy_stds": test_accuracy_stds,
            "test_accuracy": test_accuracies_per_epoch_all_runs,
            "train_accuracy": train_accuracies_per_epoch_all_runs,
            "elapsed_times": elapsed_time_all_runs,
            "train_times": train_times_per_epoch_all_runs,
            "forward_pass_times": forward_pass_times_per_epoch_all_runs,
        }
    }

    # Save the performance and hyperparameters to a pickle file
    with open(filename, 'wb') as f:
        pickle.dump(hyperparams_and_performance, f)

    # Print confirmation
    print(f"Saved performance metrics and hyperparameters to {filename}")
