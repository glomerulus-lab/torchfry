import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from Layers.RKS_Layer import RKS_Layer
from Layers.FastFood_Layer import FastFood_Layer
from NN import run_NN
import pickle
import os
from collections import namedtuple
import numpy as np

# Set device to CUDA if available, else fall back to CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Function to generate different hyperparameter combinations
def sweep_params():
    # Named tuple to hold each combination of hyperparameters
    IterationData = namedtuple("IterationData", 
        ["projection", "learnable", "learnable_gbs", "scale", "projection_dimensions", "epochs",
         "batch_size", "batch_norm", "lr"])

    # Define fixed values for some parameters
    epochs = 10
    batch_size = 512
    batch_norm = True
    lr = 0.1
    scales = [0.01, 0.1, 1, 10]
    projection_dimensions = [[4096, 4096, 4096]]

    # Iterate over combinations of projection type and learnable layers
    for projection in ["rks", "ff"]:
        n = 8 if projection == "ff" else 2  # Number of learnable configurations based on projection type

        # Generate all combinations of learnable and non-learnable settings
        for i in range(n):
            learnable = False if i == 0 else True
            learnable_gbs = [bool(int(b)) for b in f"{i:03b}"]  # Generate learnable GBS configuration

            # Yield combinations for each set of hyperparameters
            for scale in scales:
                for proj_dim in projection_dimensions:
                    yield IterationData(projection, 
                                        "NA" if projection == "ff" else learnable, 
                                        "NA" if projection == "rks" else learnable_gbs, 
                                        scale, proj_dim, epochs, batch_size, batch_norm, lr)

# Function to parse command-line arguments
def parse_all_args():
    # Set up argument parser
    parser = argparse.ArgumentParser()

    # Define arguments for various hyperparameters
    parser.add_argument("--projection", type=str, choices=["ff", "rks"], help="Projection technique desired (ff or rks)", required=True)
    parser.add_argument("--learnable", type=bool, help="Learnable Projection weights (bool)", default=False)
    parser.add_argument("--learnable_gbs", type=list[bool], default=[False, False, False], help="Learnable Projection weights (list of bools)")
    parser.add_argument("--scale", type=float, default=1.0, help="Scale for projection (float)")
    parser.add_argument("--projection_dimensions", type=list[int], default=[2048, 4096, 8192], help="Projection dims by layer (list of ints)")
    parser.add_argument("--epochs", type=int, default=10, help="Number of training epochs")
    parser.add_argument("--batch_size", type=int, default=256, help="Batch size for training")
    parser.add_argument("--batch_norm", help="Use batch normalization (bool)", default=False)
    parser.add_argument("--lr", help="Learning rate of optimizer", default=0.1)

    return parser.parse_args()

# Iterate through all parameter combinations generated by the sweep_params function
for args in sweep_params():
    print(args)

    # Define data transformations for preprocessing
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),  # Normalize data to [-1, 1] range
        transforms.Pad(2, padding_mode="edge")  # Pad images by 2 pixels (edge padding)
    ])

    # Load FashionMNIST dataset
    trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)
    testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)

    # Create data loaders for training and testing sets
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True)
    testloader = torch.utils.data.DataLoader(testset, batch_size=args.batch_size, shuffle=False)

    # Initialize model layers (moduleList will hold our layers)
    moduleList = nn.ModuleList()
    input_dim = 1024  # Initial input dimension

    # Define layers based on the projection type and configuration
    for i in range(len(args.projection_dimensions)):
        # Add projection layers based on selected type (RKS or FastFood)
        if args.projection == 'rks':
            moduleList.append(RKS_Layer(input_dim=input_dim, 
                                        output_dim=args.projection_dimensions[i], 
                                        scale=args.scale, 
                                        device=device, 
                                        learn_G=args.learnable,
                                        nonlinearity=False))
        else:  # FastFood Layer
            moduleList.append(FastFood_Layer(input_dim=input_dim, 
                                        output_dim=args.projection_dimensions[i], 
                                        scale=args.scale, 
                                        device=device, 
                                        learn_G=args.learnable_gbs[0],
                                        learn_B=args.learnable_gbs[1],
                                        learn_S=args.learnable_gbs[2],
                                        nonlinearity=False))
        
        # Optionally add batch normalization after each layer
        if args.batch_norm:
            moduleList.append(nn.BatchNorm1d(affine=False))

        # Nonlinearity (ReLU) after each layer
        moduleList.append(nn.ReLU())
        input_dim = args.projection_dimensions[i]  # Update input dimension for next layer

    # Output layer (final classification layer)
    moduleList.append(nn.Linear(input_dim, 10))  # 10 output classes for FashionMNIST

    # Initialize lists to store metrics per epoch for all runs
    train_accuracies_per_epoch_all_runs = [[] for _ in range(args.epochs)]
    test_accuracies_per_epoch_all_runs = [[] for _ in range(args.epochs)]
    elapsed_times_per_epoch_all_runs = [[] for _ in range(args.epochs)]
    test_times_per_epoch_all_runs = [[] for _ in range(args.epochs)]

    # Run the model 10 times to get accurate performance stats
    for run in range(10):
        # Run the neural network and get performance metrics for each run
        learnable_params, non_learnable_params, train_accuracies, test_accuracies, elapsed_times, test_times = run_NN(trainloader, testloader, moduleList, args.epochs, device, args.lr)

        # Store the accuracies and times for each epoch in the current run
        for epoch in range(args.epochs):
            train_accuracies_per_epoch_all_runs[epoch].append(train_accuracies[epoch])
            test_accuracies_per_epoch_all_runs[epoch].append(test_accuracies[epoch])
            elapsed_times_per_epoch_all_runs[epoch].append(elapsed_times[epoch])
            test_times_per_epoch_all_runs[epoch].append(test_times[epoch])

    # Calculate the mean and std of accuracies and times across all 10 runs for each epoch
    train_accuracy_means = [np.mean(train_accuracies_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    train_accuracy_stds = [np.std(train_accuracies_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    test_accuracy_means = [np.mean(test_accuracies_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    test_accuracy_stds = [np.std(test_accuracies_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    elapsed_time_means = [np.mean(elapsed_times_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    elapsed_time_stds = [np.std(elapsed_times_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    test_time_means = [np.mean(test_times_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]
    test_time_stds = [np.std(test_times_per_epoch_all_runs[epoch]) for epoch in range(args.epochs)]

    # Ensure directory exists to save performance metrics
    os.makedirs("testing_performance", exist_ok=True)

    # Define filename for saving results
    filename = f'testing_performance/proj={args.projection}-learn={args.learnable}-learn_gbs={args.learnable_gbs}-scale={args.scale}-projdims={args.projection_dimensions}-epoch={args.epochs}-batch_size={args.batch_size}-batch_norm={args.batch_norm}.pkl'

    # Create a dictionary to store hyperparameters and performance metrics
    hyperparams_and_performance = {
        "hyperparameters": {
            "projection": args.projection,
            "learnable": args.learnable,
            "learnable_gbs": args.learnable_gbs,
            "scale": args.scale,
            "projection_dimensions": args.projection_dimensions,
            "epochs": args.epochs,
            "batch_size": args.batch_size,
            "batch_norm": args.batch_norm
        },
        "performance": {
            "learnable_params": learnable_params,
            "non_learnable_params": non_learnable_params,
            "train_accuracy_means": train_accuracy_means,
            "test_accuracy_means": test_accuracy_means,
            "elapsed_time_means": elapsed_time_means,
            "test_time_means": test_time_means,
            "train_accuracy_stds": train_accuracy_stds,
            "test_accuracy_stds": test_accuracy_stds,
            "elapsed_time_stds": elapsed_time_stds,
            "test_time_stds": test_time_stds,
            "test_accuracy": test_accuracies_per_epoch_all_runs,
            "train_accuracy": train_accuracies_per_epoch_all_runs,
            "elapsed_times": elapsed_times_per_epoch_all_runs,
            "test_times": test_accuracies_per_epoch_all_runs  # There's a typo here, it should be test_times
        }
    }

    # Save the performance and hyperparameters to a pickle file
    with open(filename, 'wb') as f:
        pickle.dump(hyperparams_and_performance, f)

    # Print confirmation
    print(f"Saved performance metrics and hyperparameters to {filename}")
